
@article{khoury_high-precision_2009,
	title = {High-precision identification of contextual information in location-aware engineering applications},
	volume = {23},
	issn = {1474-0346},
	url = {http://www.sciencedirect.com/science/article/pii/S1474034609000184},
	doi = {10.1016/j.aei.2009.04.002},
	abstract = {This paper presents research that investigated algorithms for high-precision identification of contextual information in location-aware engineering applications. The primary contribution of the presented work is the design and implementation of a dynamic user-viewpoint tracking scheme in which mobile users’ spatial context is defined not only by their position (i.e., location), but also by their three-dimensional head orientation (i.e., line of sight). This allows the identification of objects and artifacts visible in a mobile user’s field of view with much higher accuracy than was possible by tracking position alone. For outdoor applications, a georeferencing based algorithm has been developed using the Global Positioning System (GPS) and magnetic orientation tracking devices [5] to track a user’s dynamic viewpoint. For indoor applications, this study explored the applicability of wireless technologies, in particular Indoor GPS, for dynamic user position tracking in situations where GPS is unavailable. The objectives of this paper are to describe the details of the three-stage-algorithm that has been designed and implemented, and to demonstrate the extent to which positioning technologies such as GPS and Indoor GPS can be used together with high-precision orientation trackers to accurately interpret the fully-qualified spatial context of a mobile user in challenging environments such as those found on construction sites. The obtained results highlight the potential of using location-aware technologies for rapidly identifying and retrieving contextual information in engineering applications.},
	number = {4},
	urldate = {2014-03-12},
	journal = {Advanced Engineering Informatics},
	author = {Khoury, Hiam M. and Kamat, Vineet R.},
	month = oct,
	year = {2009},
	pages = {483--496},
	file = {ScienceDirect Full Text PDF:/Users/Jonghoon_Seo/Zotero Repository/storage/J8UNQNKZ/Khoury 그리고 Kamat - 2009 - High-precision identification of contextual inform.pdf:application/pdf;ScienceDirect Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/QETKPISS/S1474034609000184.html:text/html}
}

@article{behzadan_enabling_2013,
	title = {Enabling discovery‐based learning in construction using telepresent augmented reality},
	volume = {33},
	issn = {0926-5805},
	url = {http://www.sciencedirect.com/science/article/pii/S0926580512001525},
	doi = {10.1016/j.autcon.2012.09.003},
	abstract = {Construction engineering students often complain about the lack of engagement and interaction with the learning environment. Notwithstanding, many instructors still rely on traditional teaching methods which include the use of chalkboard, handouts, and computer presentations that are often filled with many words and few visual elements. Research shows that these teaching techniques are considered almost obsolete by a many students specially those who are visual learners or team workers. Also, the influence of visual and social media has changed student perceptions and how they expect the instructional materials to be presented in a classroom setting. This paper presents an innovative pedagogical tool that uses remote videotaping, augmented reality (AR), and ultra-wide band (UWB) locationing to bring live videos of remote construction jobsites to the classroom, create an intuitive interface for students to interact with the objects in the video scenes, and visually deliver location-aware instructional materials to them.},
	urldate = {2014-03-12},
	journal = {Automation in Construction},
	author = {Behzadan, Amir H. and Kamat, Vineet R.},
	month = aug,
	year = {2013},
	pages = {3--10},
	file = {Behzadan_Kamat_2013_Enabling discovery‐based learning in construction using telepresent augmented.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/4ZBSBD6H/Behzadan_Kamat_2013_Enabling discovery‐based learning in construction using telepresent augmented.pdf:application/pdf;ScienceDirect Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/FG5HNSZ6/S0926580512001525.html:text/html}
}

@article{aziz_supporting_2012,
	title = {Supporting {Site}-{Based} {Processes} {Using} {Context}-{Aware} {Virtual} {Prototyping}},
	volume = {18},
	issn = {1076-0431},
	url = {http://ascelibrary.org/doi/abs/10.1061/%28ASCE%29AE.1943-5568.0000068},
	doi = {10.1061/(ASCE)AE.1943-5568.0000068},
	abstract = {Abstract Recent advances in the use of virtual building prototypes as a tool to support various site-based production processes coupled with improvements in context-aware mobile computing offer significant potential of improving decision making during construction phase of a building by providing relevant and timely access to design and process information. This paper investigates the scope and potential for integrating intelligent context-aware interfaces with sophisticated virtual building prototypes, to provide highly relevant and context-specific building information to concerned stakeholders throughout the building life cycle. Key enabling technologies and related literature are reviewed. Architecture to integrate context awareness with virtual building prototype is presented to allow for integration of context at various levels, and timely retrieval of building model data is presented. Conclusions are drawn about the possible future effect on the construction industry.},
	number = {2},
	urldate = {2014-03-12},
	journal = {Journal of Architectural Engineering},
	author = {Aziz, Z.},
	year = {2012},
	pages = {79--83},
	file = {Full Text PDF:/Users/Jonghoon_Seo/Zotero Repository/storage/9VVVMXMK/Aziz - 2012 - Supporting Site-Based Processes Using Context-Awar.pdf:application/pdf;Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/H3QKPBID/(ASCE)AE.1943-5568.html:text/html}
}

@article{_georeferenced_2007,
	title = {Georeferenced {Registration} of {Construction} {Graphics} in {Mobile} {Outdoor} {Augmented} {Reality}},
	volume = {21},
	issn = {0887-3801},
	url = {http://dx.doi.org/10.1061/(ASCE)0887-3801(2007)21:4(247)},
	doi = {10.1061/(ASCE)0887-3801(2007)21:4(247)},
	abstract = {This paper describes research that investigated the application of the global positioning system and 3 degree-of-freedom (3-DOF) angular tracking to address the registration problem during interactive visualization of construction graphics in outdoor augmented reality (AR) environments. The global position and the three-dimensional (3D) orientation of a user’s viewpoint are tracked, and this information is reconciled with the known global position and orientation of superimposed computer-aided design (CAD) objects. Based on this computation, the relative translation and axial rotations between the user’s viewpoint and the CAD objects are continually calculated. The relative geometric transformations are then applied to the CAD objects inside a virtual viewing frustum that is coincided with the real world space that is in the user’s view. The result is an augmented outdoor environment where superimposed graphical objects stay fixed to their real world locations as the user navigates. The algorithms are implemented in a software tool called UM-AR-GPS-ROVER that is capable of interactively placing static and dynamic 3D models at any location in outdoor augmented space. The concept and prototype are demonstrated with an example in which scheduled construction activities for the erection of a structural steel frame are graphically simulated in outdoor AR.},
	number = {4},
	urldate = {2015-06-27},
	journal = {Journal of Computing in Civil Engineering},
	year = {2007},
	pages = {247--258},
	file = {Full Text PDF:/Users/Jonghoon_Seo/Zotero Repository/storage/2ZSIF4II/2007 - Georeferenced Registration of Construction Graphic.pdf:application/pdf;Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/IR8QESSA/(ASCE)0887-3801(2007)214(247).html:text/html}
}

@article{chi_research_2013,
	series = {Augmented {Reality} in {Architecture}, {Engineering}, and {Construction}},
	title = {Research trends and opportunities of augmented reality applications in architecture, engineering, and construction},
	volume = {33},
	issn = {0926-5805},
	url = {http://www.sciencedirect.com/science/article/pii/S0926580513000022},
	doi = {10.1016/j.autcon.2012.12.017},
	abstract = {Augmented reality (AR), a state-of-the-art technology for superimposing information onto the real world, has recently started to affect our daily lives. AR applications are becoming mature and versatile. This paper discusses trends in AR applications for architecture, engineering, construction, and facility management (AEC/FM). This paper specifically focuses on four technologies—localization, natural user interface (NUI), cloud computing, and mobile devices—which have the potential to influence the development of AR applications. Advances in localization technology will enable the deployment of AR in a complex environment. An NUI provides more convenient and intuitive user experiences, which can increase the usability of AR. Cloud computing environments allow users with internet access to ubiquitously retrieve information from almost anywhere. Hence, cloud computing increases the freedom of using AR in AEC/FM applications. Another factor that will lead to the wider usage of AR is that mobile devices are becoming smaller, more powerful, and less expensive. This paper summarizes the results of 101 research efforts, and outlines the research trends and opportunities for applying AR in the fields of AEC/FM.},
	urldate = {2015-07-06},
	journal = {Automation in Construction},
	author = {Chi, Hung-Lin and Kang, Shih-Chung and Wang, Xiangyu},
	month = aug,
	year = {2013},
	pages = {116--122},
	file = {ScienceDirect Full Text PDF:/Users/Jonghoon_Seo/Zotero Repository/storage/RPA685NS/Chi et al. - 2013 - Research trends and opportunities of augmented rea.pdf:application/pdf;ScienceDirect Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/CNTZP5AA/S0926580513000022.html:text/html}
}

@article{chi_development_2012,
	series = {Evolvability of {Complex} {Systems}},
	title = {Development of user interface for tele-operated cranes},
	volume = {26},
	issn = {1474-0346},
	url = {http://www.sciencedirect.com/science/article/pii/S1474034612000481},
	doi = {10.1016/j.aei.2012.05.001},
	abstract = {This research focuses on one of the major challenges in a tele-operated crane system, namely the user interface (UI). This UI should provide rich information retrieved from the field and display it properly in order to enhance the operation and decision-making processes involved in crane activities. In this research, we have designed two UIs specifically for a tele-operated crane system. The first UI is a four view system (quad-view) with a top view, left-side view, right-side view, and global view. The second UI has four views but uses additional guidance from Augmented Reality (AR) technologies. To test the UIs, we used a robot arm (KUKA KR16) to simulate a tele-operated crane in a testing environment. We also compared the UIs we designed against a conventional operation interface (i.e. operator’s view with oral guidance from the ground). We conducted a user test with two groups of participants: 5 crane operators and 30 students. Students constitute a novice group, and their results are interpreted from a statistical perspective. Using the student group, the interface’s learning curve can be evaluated. Operators constitute an expert group, which provides evidences for evaluating if the developed UIs are realistic and fit the needs of the field. We found that use of the UIs we designed resulted in a shorter erection time (336 and 343 s) than if the participants used the conventional operation interface (380 s). A self-evaluated index showing the difficulty of the tasks, the NASA task loading index (TLX), was calculated for each of the UIs. The UIs resulted in a higher TLX (52.0 and 53.2) than the conventional operation interface (32.2). In summary, the two UIs developed in this research are able to assist operators in operating remote cranes more efficiently and with less mental load than by using the conventional operation interface.},
	number = {3},
	urldate = {2015-07-11},
	journal = {Advanced Engineering Informatics},
	author = {Chi, Hung-Lin and Chen, Yi-Chen and Kang, Shih-Chung and Hsieh, Shang-Hsien},
	month = aug,
	year = {2012},
	pages = {641--652},
	file = {Chi et al_2012_Development of user interface for tele-operated cranes.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/Z8R7UJNQ/Chi et al_2012_Development of user interface for tele-operated cranes.pdf:application/pdf;ScienceDirect Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/AVDB8TNN/S1474034612000481.html:text/html}
}

@article{shin_identification_2008,
	title = {Identification of application areas for {Augmented} {Reality} in industrial construction based on technology suitability},
	volume = {17},
	issn = {0926-5805},
	url = {http://www.sciencedirect.com/science/article/pii/S0926580508000289},
	doi = {10.1016/j.autcon.2008.02.012},
	abstract = {Research studies in the application of Augmented Reality (AR) in the Architecture, Engineering, and Construction (AEC) industry have suggested its feasibility. However, realization of the use of AR in AEC requires not only demonstration of feasibility but also validation of its suitability. This paper comprehensively identifies AR application areas in industrial construction based on suitability of AR technologies. In order to successfully explore suitability of AR, this paper assesses work tasks from the viewpoint of human factors regarding visual information requirements to find rationale for the benefits of AR in work tasks. Based on the assessment of work tasks, this paper presents a comprehensive map that identifies AR application areas in industrial construction. The comprehensive map reveals that eight work tasks (layout, excavation, positioning, inspection, coordination, supervision, commenting, and strategizing) out of 17 classified work tasks may potentially benefit from AR support.},
	number = {7},
	urldate = {2015-07-11},
	journal = {Automation in Construction},
	author = {Shin, Do Hyoung and Dunston, Phillip S.},
	month = oct,
	year = {2008},
	pages = {882--894},
	file = {ScienceDirect Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/MCKI7PGF/S0926580508000289.html:text/html;Shin_Dunston_2008_Identification of application areas for Augmented Reality in industrial.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/RTWGVP2J/Shin_Dunston_2008_Identification of application areas for Augmented Reality in industrial.pdf:application/pdf}
}

@inproceedings{song_penlight:_2009,
	title = {{PenLight}: combining a mobile projector and a digital pen for dynamic visual overlay},
	shorttitle = {{PenLight}},
	url = {http://dl.acm.org/citation.cfm?id=1518726},
	urldate = {2015-07-18},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Song, Hyunyoung and Grossman, Tovi and Fitzmaurice, George and Guimbretiere, François and Khan, Azam and Attar, Ramtin and Kurtenbach, Gordon},
	year = {2009},
	keywords = {AEC/FM: Planning, Good Univ., KEY REFERENCE, MEP(Mechanical, Electronical, Plumbing), System: Pen based, System: Projection},
	pages = {143--152},
	file = {PenLight combining a mobile projector and a digital pen for dynamic visual overlay.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/QDEG48M6/PenLight combining a mobile projector and a digital pen for dynamic visual overlay.pdf:application/pdf}
}

@article{olbrich_augmented_2013,
	title = {Augmented reality supporting user-centric building information management},
	volume = {29},
	issn = {0178-2789, 1432-2315},
	url = {http://link.springer.com/10.1007/s00371-013-0840-2},
	doi = {10.1007/s00371-013-0840-2},
	language = {en},
	number = {10},
	urldate = {2015-07-18},
	journal = {The Visual Computer},
	author = {Olbrich, Manuel and Graf, Holger and Kahn, Svenja and Engelke, Timo and Keil, Jens and Riess, Patrick and Webel, Sabine and Bockholt, Ulrich and Picinbono, Guillaume},
	month = oct,
	year = {2013},
	keywords = {AEC/FM: FM, Collaboration, Contents: BIM, Contents: MEP, FM Processes: Information Management, KEY REFERENCE, On-site annotation, System: Mobile AR},
	pages = {1093--1105},
	file = {Augmented reality supporting user-centric building information management.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/2CBXT6WE/Augmented reality supporting user-centric building information management.pdf:application/pdf}
}

@inproceedings{cote_augmented_2013,
	title = {An augmented reality tool for facilitating on-site interpretation of 2D construction drawings},
	url = {http://communities.bentley.com/cfs-file/__key/CommunityServer-Blogs-Components-WeblogFiles/00-00-00-50-35-Papers/8270.ConstructionDrawings-_2D00_-2013.pdf},
	urldate = {2015-07-18},
	booktitle = {Proceedings of the {Construction} {Applications} of {Virtual} {Reality} ({CONVR}) conference, {London}, {England}},
	author = {Côté, Stéphane and Trudel, Philippe and Snyder, Rob and Gervais, Renaud},
	year = {2013},
	keywords = {Contents: Drawing, System: Mobile AR},
	file = {AN AUGMENTED REALITY TOOL FOR FACILITATING ON-SITE INTERPRETATION OF 2D CONSTRUCTION DRAWINGS.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/BTXFW9VT/AN AUGMENTED REALITY TOOL FOR FACILITATING ON-SITE INTERPRETATION OF 2D CONSTRUCTION DRAWINGS.pdf:application/pdf}
}

@inproceedings{webster_augmented_????,
	title = {Augmented {Reality} in {Architectural} {Construction}, {Inspection}, and {Renovation}},
	url = {http://cedb.asce.org/cgi/WWWdisplay.cgi?9603695},
	language = {eng},
	urldate = {2015-07-12},
	publisher = {ASCE},
	author = {Webster, Anthony and Feiner, Steven and MacIntyre, Blair and Massie, William and Krueger, Theodore},
	pages = {913--919},
	file = {Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/9WA6ACF5/WWWdisplay.html:text/html}
}

@article{schall_handheld_2009,
	title = {Handheld {Augmented} {Reality} for underground infrastructure visualization},
	volume = {13},
	issn = {1617-4909, 1617-4917},
	url = {http://link.springer.com/10.1007/s00779-008-0204-5},
	doi = {10.1007/s00779-008-0204-5},
	language = {en},
	number = {4},
	urldate = {2015-07-18},
	journal = {Personal and Ubiquitous Computing},
	author = {Schall, Gerhard and Mendez, Erick and Kruijff, Ernst and Veas, Eduardo and Junghanns, Sebastian and Reitinger, Bernhard and Schmalstieg, Dieter},
	month = may,
	year = {2009},
	keywords = {Contents: MEP, Good Univ., KEY REFERENCE, System: Mobile AR},
	pages = {281--291},
	file = {Handheld augmented reality for underground infrastructure visualization.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/AMMCASKW/Handheld augmented reality for underground infrastructure visualization.pdf:application/pdf}
}

@article{behzadan_ubiquitous_2008,
	title = {Ubiquitous location tracking for context-specific information delivery on construction sites},
	volume = {17},
	issn = {09265805},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0926580508000186},
	doi = {10.1016/j.autcon.2008.02.002},
	language = {en},
	number = {6},
	urldate = {2015-07-18},
	journal = {Automation in Construction},
	author = {Behzadan, Amir H. and Aziz, Zeeshan and Anumba, Chimay J. and Kamat, Vineet R.},
	month = aug,
	year = {2008},
	keywords = {AEC/FM: Construction, Contents: Model, Outdoor, System: Mobile AR},
	pages = {737--748},
	file = {Ubiquitous location tracking for context-specific information delivery on construction sites.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/WSDZWRWC/Ubiquitous location tracking for context-specific information delivery on construction sites.pdf:application/pdf}
}

@inproceedings{machino_remote-collaboration_2006,
	title = {Remote-collaboration system using mobile robot with camera and projector},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1642326},
	urldate = {2015-07-18},
	booktitle = {Robotics and {Automation}, 2006. {ICRA} 2006. {Proceedings} 2006 {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Machino, Tamotsu and Iwaki, Satoshi and Kawata, Hiroaki and Yanagihara, Yoshimasa and Nanjo, Yoshito and Shimokura, Ken-ichiro},
	year = {2006},
	keywords = {Collaboration, Contents: Annotation, System: Projection},
	pages = {4063--4068},
	file = {Remote-Collaboration System Using Mobile Robot with Camera and Projection.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/CPAFU5ZS/Remote-Collaboration System Using Mobile Robot with Camera and Projection.pdf:application/pdf}
}

@article{ammari_collaborative_2014,
	title = {Collaborative {BIM}-based markerless mixed reality framework for facilities maintenance},
	url = {http://ascelibrary.org/doi/abs/10.1061/9780784413616.082},
	urldate = {2015-07-18},
	journal = {Computing in Civil and Building Engineering},
	author = {Ammari, K. and Hammad, Amin},
	year = {2014},
	keywords = {Contents: Annotation+BIM info, System: Mobile AR},
	pages = {657--664},
	file = {Collaborative BIM-based Markerless Mixed Reality Framework for Facilities Maintenance.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/2NVQZF8V/Collaborative BIM-based Markerless Mixed Reality Framework for Facilities Maintenance.pdf:application/pdf}
}

@article{yeh_-site_2012,
	title = {On-site building information retrieval by using projection-based augmented reality},
	url = {http://ascelibrary.org/doi/10.1061/(ASCE)CP.1943-5487.0000156},
	urldate = {2015-07-18},
	journal = {Journal of Computing in Civil Engineering},
	author = {Yeh, Kai-Chen and Tsai, Meng-Han and Kang, Shih-Chung},
	year = {2012},
	keywords = {Contents: Drawing, Geometry information, KEY REFERENCE, System: Projection},
	file = {On-site building information retrieval by using projection-based augmented reality.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/WMNXFTJX/On-site building information retrieval by using projection-based augmented reality.pdf:application/pdf}
}

@article{kwon_defect_2014,
	title = {A defect management system for reinforced concrete work utilizing {BIM}, image-matching and augmented reality},
	volume = {46},
	issn = {09265805},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0926580514001162},
	doi = {10.1016/j.autcon.2014.05.005},
	language = {en},
	urldate = {2015-07-18},
	journal = {Automation in Construction},
	author = {Kwon, Oh-Seong and Park, Chan-Sik and Lim, Chung-Rok},
	month = oct,
	year = {2014},
	keywords = {AEC/FM: Construction, Contents: MEP, System: Mobile AR},
	pages = {74--81},
	file = {A defectmanagement systemfor reinforced concrete work utilizing BIM,.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/JPE62UJQ/A defectmanagement systemfor reinforced concrete work utilizing BIM,.pdf:application/pdf}
}

@inproceedings{ebbesen_information_2015,
	series = {{EuroFM} {Research} {Papers}},
	title = {Information {Technology} in {Facilities} {Management} - {A} {Literature} {Review}},
	url = {http://orbit.dtu.dk/fedora/objects/orbit:138824/datastreams/file_7ee4a292-7ec3-4d6a-a8fc-3349bde0ce64/content},
	booktitle = {Research {Papers}. {Advancing} {Knowledge} in {Facilities} {Management}: {People} make {Facilities} {Management}},
	publisher = {EuroFM},
	author = {Ebbesen, Poul},
	year = {2015},
	keywords = {AEC/FM: FM, KEY REFERENCE, Review paper},
	file = {Ebbesen_2015_Information Technology in Facilities Management - A Literature Review.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/8UNAJRRX/Ebbesen_2015_Information Technology in Facilities Management - A Literature Review.pdf:application/pdf;forskningsdatabasen.dk:/Users/Jonghoon_Seo/Zotero Repository/storage/EWGII4KV/Share.html:text/html}
}

@article{lin_using_2014,
	title = {Using {Augmented} {Reality} in a {Multiscreen} {Environment} for {Construction} {Discussion}},
	volume = {0},
	issn = {0887-3801},
	url = {http://dx.doi.org/10.1061/(ASCE)CP.1943-5487.0000420},
	doi = {10.1061/(ASCE)CP.1943-5487.0000420},
	abstract = {AbstractDiscussion is critical in identifying, predicting, and resolving potential problems in the field of construction. This process relies heavily on oral communication with the assistance of construction drawings, schedules, and other related documents. Because most construction projects include multiple working phases and involve multiple parties, it is difficult for participants to clearly grasp the whole picture of a construction site and to make accurate predictions about future activities. In this research, the authors proposed a visualized environment to facilitate the discussion process. It includes a stationary display called BIM Table for displaying public information and for collaboration among disciplines, and multiple mobile devices for showing private information. The authors employed augmented reality technologies to connect the BIM Table and the mobile devices as well as the public and private information. The authors named this discussion environment augmented reality and multiscreen (AR-MS) system. This system aims to reduce the complexity of discussion information while keeping necessary information available during the entire discussion process. To validate the AR-MS system, a user test with 36 participants (N=36) was conducted. The participants were required to perform the three tasks: Data-finding (DF), problem prediction (PP), and decision-making (DM) using both the AR-MS system and the conventional paper-based method. This research discovered that the completion time is significantly shortened using the AR-MS system in both DF and PP tasks, while the accuracy in all three tasks showed no significant difference between AR-MS system and conventional method. Based on the results, the AR-MS system can be of benefit in information searching and foreseeing potential problems on a construction site and the discussion process can be made more effective and efficient by its use.},
	number = {0},
	urldate = {2015-07-18},
	journal = {Journal of Computing in Civil Engineering},
	author = {Lin, Tin-Hui and Liu, Chao-Hsiang and Tsai, Meng-Han and Kang, Shih-Chung},
	month = jul,
	year = {2014},
	keywords = {AEC/FM: Construction, Collaboration, Construction의 느낌보다는 설계 단계, for: 논문 3, KEY REFERENCE, System: Desktop AR},
	pages = {04014088},
	file = {Lin et al_0_Using Augmented Reality in a Multiscreen Environment for Construction Discussion.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/4M5PUW5Z/Lin et al_0_Using Augmented Reality in a Multiscreen Environment for Construction Discussion.pdf:application/pdf;Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/FPBIDFBS/(ASCE)CP.1943-5487.html:text/html}
}

@article{hou_combining_2014,
	title = {Combining {Photogrammetry} and {Augmented} {Reality} {Towards} an {Integrated} {Facility} {Management} {System} for the {Oil} {Industry}},
	volume = {102},
	issn = {0018-9219},
	doi = {10.1109/JPROC.2013.2295327},
	abstract = {The capabilities of applying smart information management systems for facility management (FM) in oil refining context have not yet been fully exploited. This paper presents a study that investigates the applicability of integrating advanced technologies such as augmented virtuality (AV), augmented reality (AR), and server-sustained information modeling (IM) in facilitating FM activities for a petroleum refinery. The paper starts with a thorough review on previous work in which multiple information processing technologies are applied to aid FM. The following section presents the conceivable merits when the novel visualization is formulated to enhance the conventional IM application. It then proposes a novel system framework based on technological feasibility and further describes the development of a system prototype that boosts immersive and interactive experiences to FM toward a multitude of electrical components. It is noted that this paper focuses on the method for the technological realization of the system. With the successful development of the system, it is able to deal with the management of complex information flows, support the users' navigation in geo-coordinates, and enables a succinct smart IM interface with switchable AV/AR scenes. In view that IM has been proved suitable in supporting real-time communication and information management while AV/AR can be effectively used to improve the way how information is exhibited into real workspaces, the system proves the concept of IM+AV/AR in the context of FM in a refinery. Future work will be conducted on the evaluation of system effectiveness and system optimization, with the aim of functional improvement and performing a feasibility study.},
	number = {2},
	journal = {Proceedings of the IEEE},
	author = {Hou, Lei and Wang, Ying and Wang, Xiangyu and Maynard, N. and Cameron, I. and Zhang, Shaohua and Maynard, Y.},
	month = feb,
	year = {2014},
	keywords = {AEC/FM: FM, Contents: Model, FM Processes: Information Management, Maintenance, System: AR/VR},
	pages = {204--220},
	file = {Hou et al_2014_Combining Photogrammetry and Augmented Reality Towards an Integrated Facility.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/GFCX5VQ9/Hou et al_2014_Combining Photogrammetry and Augmented Reality Towards an Integrated Facility.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/Jonghoon_Seo/Zotero Repository/storage/2CZQQKFU/abs_all.html:text/html}
}

@incollection{_grand_????,
	title = {Grand {Challenges} in {Data} and {Information} {Visualization} for the {Architecture}, {Engineering}, {Construction}, and {Facility} {Management} {Industries}},
	isbn = {978-0-7844-1302-9},
	url = {http://ascelibrary.org/doi/abs/10.1061/9780784413029.106},
	abstract = {This study aims to identify challenges in the AEC/FM industry that can potentially be addressed using research in data and information visualization. These challenges were recognized by: reviewing visualization techniques for addressing current challenges associated with decision-making tasks; studying the fit between visualization techniques and the decision-making tasks; identifying the gaps in knowledge of visualization techniques; and, finally, establishing a framework for measuring the domain requirements and the technology capabilities as a road map for domain-needs-driven development in the area of data and information visualization. The challenges associated with the current practice of project delivery and the limitations of the state-of-the-art visualization techniques in addressing these challenges are discussed. This paper presents where and how intuitive and effective visualization can address these challenges. It also suggests areas where researchers can apply visualization research to further improve existing processes.},
	urldate = {2015-07-18},
	booktitle = {Computing in {Civil} {Engineering} (2013)},
	publisher = {American Society of Civil Engineers},
	keywords = {AEC/FM, Data Visualization, Information Visualization},
	pages = {849--856},
	file = {Grand Challenges in Data and Information Visualization for the Architecture,.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/ISMU67SZ/Grand Challenges in Data and Information Visualization for the Architecture,.pdf:application/pdf;Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/FEZI29KI/9780784413029.html:text/html}
}

@article{williams_bim2mar:_2015,
	title = {{BIM}2MAR: {An} {Efficient} {BIM} {Translation} to {Mobile} {Augmented} {Reality} {Applications}},
	volume = {31},
	issn = {0742-597X, 1943-5479},
	shorttitle = {{BIM}2MAR},
	url = {http://ascelibrary.org/doi/10.1061/%28ASCE%29ME.1943-5479.0000315},
	doi = {10.1061/(ASCE)ME.1943-5479.0000315},
	language = {en},
	number = {1},
	urldate = {2015-07-18},
	journal = {Journal of Management in Engineering},
	author = {Williams, Graceline and Gheisari, Masoud and Chen, Po-Jui and Irizarry, Javier},
	month = jan,
	year = {2015},
	keywords = {AECO : Architecture, Engineering, Construction, Operation, BIM, Good Univ., Mobile AR 을 통한 BIM, System: Mobile AR},
	pages = {A4014009},
	file = {Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/MWKTKPVF/(ASCE)ME.1943-5479.html:text/html;Williams et al_2015_BIM2MAR.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/FT2P4SWN/Williams et al_2015_BIM2MAR.pdf:application/pdf}
}

@article{bae_high-precision_2013,
	title = {High-precision vision-based mobile augmented reality system for context-aware architectural, engineering, construction and facility management ({AEC}/{FM}) applications},
	volume = {1},
	issn = {2213-7459},
	url = {http://link.springer.com/article/10.1186/2213-7459-1-3},
	doi = {10.1186/2213-7459-1-3},
	abstract = {Background Many context-aware techniques have been proposed to deliver cyber-information, such as project specifications or drawings, to on-site users by intelligently interpreting their environment. However, these techniques primarily rely on RF-based location tracking technologies (e.g., GPS or WLAN), which typically do not provide sufficient precision in congested construction sites or require additional hardware and custom mobile devices. Method This paper presents a new vision-based mobile augmented reality system that allows field personnel to query and access 3D cyber-information on-site by using photographs taken from standard mobile devices. The system does not require any location tracking modules, external hardware attachments, and/or optical fiducial markers for localizing a user’s position. Rather, the user’s location and orientation are purely derived by comparing images from the user’s mobile device to a 3D point cloud model generated from a set of pre-collected site photographs. Results The experimental results show that 1) the underlying 3D reconstruction module of the system generates complete 3D point cloud models of target scene, and is up to 35 times faster than other state-of-the-art Structure-from-Motion (SfM) algorithms, 2) the localization time takes at most few seconds in actual construction site. Conclusion The localization speed and empirical accuracy of the system provides the ability to use the system on real-world construction sites. Using an actual construction case study, the perceived benefits and limitations of the proposed method for on-site context-aware applications are discussed in detail.},
	language = {en},
	number = {1},
	urldate = {2015-07-18},
	journal = {Visualization in Engineering},
	author = {Bae, Hyojoon and Golparvar-Fard, Mani and White, Jules},
	month = jun,
	year = {2013},
	keywords = {AEC/FM, System: Mobile AR},
	pages = {1--13},
	file = {Bae et al_2013_High-precision vision-based mobile augmented reality system for context-aware.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/742MZT5Z/Bae et al_2013_High-precision vision-based mobile augmented reality system for context-aware.pdf:application/pdf;Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/7T279DR7/2213-7459-1-3.html:text/html}
}

@article{wang_augmented_2013,
	title = {Augmented {Reality} in built environment: {Classification} and implications for future research},
	volume = {32},
	issn = {0926-5805},
	shorttitle = {Augmented {Reality} in built environment},
	url = {http://www.sciencedirect.com/science/article/pii/S0926580512002166},
	doi = {10.1016/j.autcon.2012.11.021},
	abstract = {Augmented Reality (AR) has the potential to change how people interact and experience their surrounding environment. During the last decade a considerable amount of research has been undertaken within the built environment. With this in mind, this paper aims to provide a state-of-the-art review of mainstream studies undertaken between 2005 and 2011 within the normative literature. We found that a total of 120 articles were published in the normative built environment literature within this period. Articles were classified according to their concept and theory, implementation, evaluation (effectiveness and usability) and industrial adoption. The classification of the literature has enabled gaps in the AR literature to be identified and future research directions to be proposed.},
	urldate = {2015-07-19},
	journal = {Automation in Construction},
	author = {Wang, Xiangyu and Kim, Mi Jeong and Love, Peter E. D. and Kang, Shih-Chung},
	month = jul,
	year = {2013},
	keywords = {2005 {\textasciitilde} 2011 까지의 Rearsh  조사 논문]},
	pages = {1--13},
	file = {ScienceDirect Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/2NK4N8NE/S0926580512002166.html:text/html;Wang et al_2013_Augmented Reality in built environment.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/5AEIS2RS/Wang et al_2013_Augmented Reality in built environment.pdf:application/pdf}
}

@inproceedings{machino_robot-augmented_2005,
	title = {Robot-augmented communication: a remote-collaboration system based on a shared field of view in real space},
	shorttitle = {Robot-augmented communication},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1545507},
	urldate = {2015-07-19},
	booktitle = {Intelligent {Robots} and {Systems}, 2005.({IROS} 2005). 2005 {IEEE}/{RSJ} {International} {Conference} on},
	publisher = {IEEE},
	author = {Machino, Tamotsu and Nanjo, Yoshito and Yanagihara, Yoshimasa and Kawata, Hiroaki and Iwaki, Satoshi and Shimokura, Ken-ichiro},
	year = {2005},
	keywords = {Collaboration},
	pages = {2203--2209},
	file = {Robot-augmented communication a remote-collaboration system based on a shared field of view in real space.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/6REH7WPA/Robot-augmented communication a remote-collaboration system based on a shared field of view in real space.pdf:application/pdf}
}

@book{shen_collaborative_2009,
	title = {Collaborative {Construction} {Information} {Management}},
	isbn = {978-1-134-01390-6},
	abstract = {Most construction projects are large and costly. Collaborative working involves two or more stakeholders sharing their efforts and resources to complete the project more effectively and efficiently.  Collaborative, integrative and multi-disciplinary teams can tackle the complex issues involved in creating a viable built environment. This tends to be looked at from three interrelated perspectives: the technological, organizational, and social; and of these the key issue is to improve productivity and enable innovation through the empowerment and motivation of people.  This book provides insights for researchers and practitioners in the building and construction industry as well as graduate students, written by an international group of leading scholars and professionals into the potential use, development and limitations of current collaborative technologies and practices. Material is grouped into the themes of advanced technologies for collaborative working, virtual prototyping in design and construction, building information modelling, managing the collaborative processes, and human issues in collaborative working.},
	language = {en},
	publisher = {Routledge},
	author = {Shen, Geoffrey and Brandon, Peter and Baldwin, Andrew},
	month = jun,
	year = {2009},
	keywords = {Collaboration}
}

@inproceedings{etzold_karbon:_2014,
	address = {New York, NY, USA},
	series = {{CSCW} {Companion} '14},
	title = {{kARbon}: {A} {Collaborative} {MR} {Web} {Application} for {Communicationsupport} in {Construction} {Scenarios}},
	isbn = {978-1-4503-2541-7},
	shorttitle = {{kARbon}},
	url = {http://doi.acm.org/10.1145/2556420.2556793},
	doi = {10.1145/2556420.2556793},
	abstract = {kARbon demonstrates a web-based mixed reality (MR) support and collaboration tool for a wide range of construction planning and supervising scenarios. We describe how the construction process can be supported for locally distributed workers, experts and decision makers by leveraging MR methods in combination with effective and pure web-based collaboration, interaction and presentation concepts. kARbon therefore combines classical CAD planning data with photo collections representing temporal snapshots of the associated construction site in a precise MR scene. We focus on our collaborative use case and describe how involved people in different locations and on different device types can collaborate and interact through our tool based on the power of modern web standards.},
	urldate = {2015-07-19},
	booktitle = {Proceedings of the {Companion} {Publication} of the 17th {ACM} {Conference} on {Computer} {Supported} {Cooperative} {Work} \& {Social} {Computing}},
	publisher = {ACM},
	author = {Etzold, Jonas and Grimm, Paul and Schweitzer, Jörg and Dörner, Ralf},
	year = {2014},
	keywords = {Collaboration},
	pages = {9--12},
	file = {ACM Full Text PDF:/Users/Jonghoon_Seo/Zotero Repository/storage/DM5VAXN4/Etzold et al. - 2014 - kARbon A Collaborative MR Web Application for Com.pdf:application/pdf}
}

@article{golparvar-fard_d4ar4-dimensional_2009,
	title = {D4AR–a 4-dimensional augmented reality model for automating construction progress monitoring data collection, processing and communication},
	volume = {14},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.416.4584&rep=rep1&type=pdf},
	urldate = {2015-07-19},
	journal = {Journal of information technology in construction},
	author = {Golparvar-Fard, Mani and Peña-Mora, F. and Savarese, S.},
	year = {2009},
	keywords = {AEC/FM: Construction, Good Univ., Monitoring, System: Desktop AR},
	pages = {129--153},
	file = {D4AR–a 4-dimensional augmented reality model for automating construction progress monitoring data collection, processing and communication.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/NH9F6MRE/D4AR–a 4-dimensional augmented reality model for automating construction progress monitoring data collection, processing and communication.pdf:application/pdf}
}

@article{hammad_distributed_2009,
	title = {Distributed augmented reality for visualizing collaborative construction tasks},
	url = {http://ascelibrary.org/doi/10.1061/(ASCE)0887-3801(2009)23%3A6(418)},
	urldate = {2015-07-19},
	journal = {Journal of computing in civil engineering},
	author = {Hammad, Amin and Wang, Hui and Mudur, Sudhir P.},
	year = {2009},
	keywords = {AEC/FM: Construction, Collaboration, System: HMD, System: Mobile AR},
	file = {Distributed Augmented Reality for Visualizing Collaborative.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/NS4MH26C/Distributed Augmented Reality for Visualizing Collaborative.pdf:application/pdf}
}

@article{_interactive_2012,
	title = {Interactive {Modeler} for {Construction} {Equipment} {Operation} {Using} {Augmented} {Reality}},
	volume = {26},
	issn = {0887-3801},
	url = {http://dx.doi.org/10.1061/(ASCE)CP.1943-5487.0000137},
	doi = {10.1061/(ASCE)CP.1943-5487.0000137},
	abstract = {AbstractTo ensure an efficient and safe construction operation, efforts have been made to develop a planning tool that focuses on equipment utilization. With the development of augmented reality (AR) technology came an opportunity for collaborative and interactive scenario modelling of construction equipment operation. This paper presents a system for identifying the optimum scenario for equipment operation by intuitively operating the equipment in an AR environment. Augmented reality was coupled with transmission control protocol/internet protocol (TCP/IP) socket programming to form an interactive interface for multiple users. In this system, users can develop a construction scenario involving equipment operation and site conditions such as project progress and share the idea with other users in distant locations. The interactive modeler can test various situations to find the particular scenario that works the best under the surrounding spatial constraints. A case study involving construction of a real cable-stayed bridge shows that the system has strong potential for significant improvement in construction planning processes.},
	number = {3},
	urldate = {2015-07-23},
	journal = {Journal of Computing in Civil Engineering},
	year = {2012},
	pages = {331--341},
	file = {2012_Interactive Modeler for Construction Equipment Operation Using Augmented Reality.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/PZ6CIJQK/2012_Interactive Modeler for Construction Equipment Operation Using Augmented Reality.pdf:application/pdf;Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/K9VGGTB9/(ASCE)CP.1943-5487.html:text/html}
}

@inproceedings{ishii_augmented_2002,
	address = {Washington, DC, USA},
	series = {{ISMAR} '02},
	title = {Augmented {Urban} {Planning} {Workbench}: {Overlaying} {Drawings}, {Physical} {Models} and {Digital} {Simulation}},
	isbn = {0-7695-1781-1},
	shorttitle = {Augmented {Urban} {Planning} {Workbench}},
	url = {http://dl.acm.org/citation.cfm?id=850976.854980},
	abstract = {There is a problem in the spatial and temporal separation between the varying forms of representation used in urban design. Sketches, physical models, and more recently computational simulation, while each serving a useful purpose, tend to be incompatible formsof representation. The contemporary designer is required assimilate these divergent media into a single mental construct and in so doing is distracted from the central process of design.We propose an Augmented Reality Workbench called "Luminous Table" that attempts to address this issue by integrating multiple forms of physical and digital representations. 2D drawings, 3D physical models, and digital simulation are overlaid into a single information space in order to support the urban design process. We describe how the system was used in a graduate design course and discuss how the simultaneous use of physical and digital media allowed for a more holistic design approach. We also discuss the need for future technical improvements.},
	urldate = {2015-07-23},
	booktitle = {Proceedings of the 1st {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	publisher = {IEEE Computer Society},
	author = {Ishii, Hiroshi and Ben-Joseph, Eran and Underkoffler, John and Yeung, Luke and Chak, Dan and Kanji, Zahra and Piper, Ben},
	year = {2002},
	keywords = {Contents: Drawing, Contents: Model, KEY REFERENCE, System: Interactive Surface, System: Projection},
	pages = {203--},
	file = {Ishii et al_2002_Augmented Urban Planning Workbench.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/6QG56IKW/Ishii et al_2002_Augmented Urban Planning Workbench.pdf:application/pdf}
}

@article{dong_collaborative_2013,
	title = {Collaborative visualization of engineering processes using tabletop augmented reality},
	volume = {55},
	issn = {0965-9978},
	url = {http://www.sciencedirect.com/science/article/pii/S0965997812001287},
	doi = {10.1016/j.advengsoft.2012.09.001},
	abstract = {3D computer visualization has emerged as an advanced problem-solving tool for engineering education and practice. For example in civil engineering, the integration of 3D/4D CAD models in the construction process helps to minimize the misinterpretation of the spatial, temporal, and logical aspects of construction planning information. Yet despite the advances made in visualization, the lack of collaborative problem-solving abilities leaves outstanding challenges that need to be addressed before 3D visualization can become widely accepted in the classroom and in professional practice. The ability to smoothly and naturally interact in a shared workspace characterizes a collaborative learning process. This paper introduces tabletop Augmented Reality to accommodate the need to collaboratively visualize computer-generated models. A new software program named ARVita is developed to validate this idea, where multiple users wearing Head-Mounted Displays and sitting around a table can all observe and interact with dynamic visual simulations of engineering processes. The applications of collaborative visualization using Augmented Reality are reviewed, the technical implementation is covered, and the program’s underlying tracking libraries are presented.},
	urldate = {2015-07-23},
	journal = {Advances in Engineering Software},
	author = {Dong, Suyang and Behzadan, Amir H. and Chen, Feng and Kamat, Vineet R.},
	month = jan,
	year = {2013},
	keywords = {Collaboration, Contents: Model, Contents: Planning Animation, System: Desktop AR},
	pages = {45--55},
	file = {Dong et al_2013_Collaborative visualization of engineering processes using tabletop augmented.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/MZPSGRB3/Dong et al_2013_Collaborative visualization of engineering processes using tabletop augmented.pdf:application/pdf;ScienceDirect Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/9743227G/S0965997812001287.html:text/html}
}

@incollection{ismail_survey_2009,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Survey on {Collaborative} {AR} for {Multi}-user in {Urban} {Studies} and {Planning}},
	copyright = {©2009 Springer Berlin Heidelberg},
	isbn = {978-3-642-03363-6, 978-3-642-03364-3},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-03364-3_53},
	abstract = {This paper describes an augmented reality (AR) environment that allows multiple participants or multi-user to interact with 2D and 3D data. AR simply can provide a collaborative interactive AR environment for urban planning, where users can interact naturally and intuitively. In addition, the collaborative AR makes multi-user in urban planning to share simultaneously a real world and virtual world. The fusion between real and virtual world, existed in AR environment by see-through HMDs, achieves higher interactivity as a key features of collaborative AR. In real-time, precise registration between both worlds and multi-user are crucial for the collaborations. Collaborative AR allow multi-user to simultaneously share a real world surrounding them and a virtual world. Common problems in AR environment will be discussed and major issues in collaborative AR will be explained details in this survey. The features of collaboration in AR environment are will be identified and the requirements of collaborative AR will be defined. This paper will give an overview on collaborative AR environment for multi-user in urban studies and planning. The work will also cover numerous systems of collaborative AR environments for multi-user.},
	language = {en},
	number = {5670},
	urldate = {2015-07-23},
	booktitle = {Learning by {Playing}. {Game}-based {Education} {System} {Design} and {Development}},
	publisher = {Springer Berlin Heidelberg},
	author = {Ismail, Ajune Wanis and Sunar, Mohd Shahrizal},
	editor = {Chang, Maiga and Kuo, Rita and Kinshuk and Chen, Gwo-Dong and Hirose, Michitaka},
	year = {2009},
	pages = {444--455},
	file = {Ismail_Sunar_2009_Survey on Collaborative AR for Multi-user in Urban Studies and Planning.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/5RG93E2I/Ismail_Sunar_2009_Survey on Collaborative AR for Multi-user in Urban Studies and Planning.pdf:application/pdf;Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/CENP33H2/978-3-642-03364-3_53.html:text/html}
}

@article{wagner_building_2012,
	title = {Building {Urban} {Narratives}: {Collaborative} {Site}-{Seeing} and {Envisioning} in the {MR} {Tent}},
	volume = {21},
	issn = {0925-9724, 1573-7551},
	shorttitle = {Building {Urban} {Narratives}},
	url = {http://link.springer.com/article/10.1007/s10606-011-9152-0},
	doi = {10.1007/s10606-011-9152-0},
	abstract = {The focus of this paper is on studying mixed teams of urban planners, citizens and other stakeholders co-constructing their vision for the future of a site. The MR Tent provides a very specific collaborative setting: an assembly of technologies brought outdoors onto the site of an urban project, which offers vistas onto the site as well as a multiplicity of representations of the site to work with, in different media and taken from different perspectives. The prime focus of this paper is on the complex narratives participants co-constructed in three participatory workshops, with the aim to understand how the core aspects of the MR Tent—spatiality, representation and haptic engagement—shape these narratives. Main findings of this research concern: how the design of the multi-layered space of the MR-Tent supports spatial story-telling; how the different representations of the site of an urban project offer the opportunity to choreograph a ‘site-seeing’ that helps participants understand the site and plan interventions; how the ‘tangibles’ in the MR-Tent encourage a different way of contributing to a shared project and ‘building a vision’.},
	language = {en},
	number = {1},
	urldate = {2015-07-23},
	journal = {Computer Supported Cooperative Work (CSCW)},
	author = {Wagner, Ina},
	month = jan,
	year = {2012},
	keywords = {AEC/FM: Planning, Collaboration, Contents: Model, System: Interactive Surface, System: Tangible UI},
	pages = {1--42},
	file = {Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/PIQN4424/s10606-011-9152-0.html:text/html;Wagner_2012_Building Urban Narratives.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/SE3DSF8X/Wagner_2012_Building Urban Narratives.pdf:application/pdf}
}

@article{shen_systems_2010,
	series = {Enabling {Technologies} for {Collaborative} {Design}},
	title = {Systems integration and collaboration in architecture, engineering, construction, and facilities management: {A} review},
	volume = {24},
	issn = {1474-0346},
	shorttitle = {Systems integration and collaboration in architecture, engineering, construction, and facilities management},
	url = {http://www.sciencedirect.com/science/article/pii/S1474034609000664},
	doi = {10.1016/j.aei.2009.09.001},
	abstract = {With the rapid advancement of information and communication technologies, particularly Internet and Web-based technologies during the past 15 years, various systems integration and collaboration technologies have been developed and deployed to different application domains, including architecture, engineering, construction, and facilities management (AEC/FM). These technologies provide a consistent set of solutions to support the collaborative creation, management, dissemination, and use of information through the entire product and project lifecycle, and further to integrate people, processes, business systems, and information more effectively. This paper presents a comprehensive review of research literature on systems integration and collaboration in AEC/FM, and discusses challenging research issues and future research opportunities.},
	number = {2},
	urldate = {2015-07-25},
	journal = {Advanced Engineering Informatics},
	author = {Shen, Weiming and Hao, Qi and Mak, Helium and Neelamkavil, Joseph and Xie, Helen and Dickinson, John and Thomas, Russ and Pardasani, Ajit and Xue, Henry},
	month = apr,
	year = {2010},
	keywords = {Contents: Objects, FM Processes: AEC-FM, FM Processes: Information Management, KEY REFERENCE, System RFID, System: Web},
	pages = {196--207},
	file = {ScienceDirect Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/F64XN5DD/S1474034609000664.html:text/html;Shen et al_2010_Systems integration and collaboration in architecture, engineering,.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/VHVQNIWK/Shen et al_2010_Systems integration and collaboration in architecture, engineering,.pdf:application/pdf}
}

@article{klein_imaged-based_2012,
	title = {Imaged-based verification of as-built documentation of operational buildings},
	volume = {21},
	issn = {0926-5805},
	url = {http://www.sciencedirect.com/science/article/pii/S0926580511001129},
	doi = {10.1016/j.autcon.2011.05.023},
	abstract = {As-built models and drawings are essential documents used during the operations and maintenance (O\&amp;M) of buildings for a variety of purposes including the management of facility spaces, equipment, and energy systems. These documents undergo continuous verification and updating procedures both immediately after construction during the initial handover process to reflect construction changes and during occupancy stage for the changes that occur throughout the building's lifespan. Current as-built verification and updating procedures involve largely time consuming on-site surveys, where measurements are taken and recorded manually. In an attempt to streamline this process, the paper investigates the advantages and limitations of using photogrammetric image processing to document and verify actual as-built conditions. A test bed of both the interior and exterior of a university building is used to compare the dimensions generated by automated image processing to dimensions gathered through the manual survey process currently employed by facilities management and strategies for improved accuracy are investigated. Both manual and image-based dimensions are then used to verify dimensions of an existing as-built Building Information Model (BIM). Finally, the potential of the image-based spatial data is assessed for accurately generating 3D models.},
	urldate = {2015-07-25},
	journal = {Automation in Construction},
	author = {Klein, Laura and Li, Nan and Becerik-Gerber, Burcin},
	month = jan,
	year = {2012},
	keywords = {Contents: BIM, FM Processes: Information Management},
	pages = {161--171},
	file = {Klein et al_2012_Imaged-based verification of as-built documentation of operational buildings.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/ACKBZJQG/Klein et al_2012_Imaged-based verification of as-built documentation of operational buildings.pdf:application/pdf;ScienceDirect Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/PVBPPKCW/S0926580511001129.html:text/html}
}

@article{east_facility_2013,
	title = {Facility {Management} {Handover} {Model} {View}},
	volume = {27},
	issn = {0887-3801},
	url = {http://dx.doi.org/10.1061/(ASCE)CP.1943-5487.0000196},
	doi = {10.1061/(ASCE)CP.1943-5487.0000196},
	abstract = {AbstractCurrent specifications for facility handover information require contractors to produce and deliver a set of documents that provide little practical value to the facility manager. Facility managers begin their duties by rekeying the information found in these handover documents. This paper describes the facility management handover (FM) model view definition (MVD), an open-standard information exchange format that may replace current construction handover document requirements. The work was accomplished in conjunction with three buildingSMART chapters to ensure the widest possible international acceptance. The specification of the underlying industry foundation class (IFC) model with required business rules for use in the United States is called the construction-operations building information exchange (COBie) format. Procedures used to test software production and consumption of COBie were developed. Use of COBie has now been documented in several case studies.},
	number = {1},
	urldate = {2015-07-25},
	journal = {Journal of Computing in Civil Engineering},
	author = {East, William and Nisbet, Nicholas and Liebich, Thomas},
	year = {2013},
	keywords = {Contents: BIM, FM Processes: AEC-FM, FM Processes: Information Management},
	pages = {61--67},
	file = {2013_Facility Management Handover Model View.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/EM5W25DW/2013_Facility Management Handover Model View.pdf:application/pdf;Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/XDC2XXFR/(ASCE)CP.1943-5487.html:text/html}
}

@article{jung_productive_2014,
	title = {Productive modeling for development of as-built {BIM} of existing indoor structures},
	volume = {42},
	issn = {0926-5805},
	url = {http://www.sciencedirect.com/science/article/pii/S0926580514000466},
	doi = {10.1016/j.autcon.2014.02.021},
	abstract = {The as-built building information model (BIM) has a huge potential for enhancing the efficiency of building and maintenance operations. To facilitate existing-structure data acquisition for the as-built BIM, a terrestrial laser scanner, which is fast, simple to use, and yet highly accurate, is widely employed. However, as-built BIM creation of building interiors using scanned point clouds incurs critical difficulties: the complex design of indoor structures, not to mention obstacles, necessitates time-consuming manual operation and resultantly huge data sizes, which often leads to system slow-down or failure. To manage this problem, most of the recent and current research has looked to full automation; yet facility management personnel still rely on traditional field measurements because their qualitative results can only be obtained under ideal conditions or with some errors. Alternatively, in this paper, a more practical semi-automatic methodology for improved productivity of as-built BIM creation with respect to large and complex indoor environments is proposed. The proposed approach produces three-dimensional (3D) geometric drawings through three steps: segmentation for plane extraction, refinement for removal of noisy points, and boundary tracing for outline extraction. The experimental results for two test sites, a relatively simple corridor and a complex atrium, showed a high data-size reduction rate: to 3.8 and 4.3\% of the original sizes, out of 51.5 and 111.5 million points, respectively. Based on the automatically produced geometric drawings and the remaining points, manual as-built BIM creation was conducted. Using the extracted lines as guides, each object and its relationship were more easily identified and modeled. At the same time, the great reduction in the point clouds' data sizes enabled the modeler, using the BIM software, to efficiently manipulate the geometric drawing without system slow-down or failure. The proposed approach was shown to be a potentially effective means of improving productivity and reliability in complex indoor as-built BIM production.},
	urldate = {2015-07-25},
	journal = {Automation in Construction},
	author = {Jung, Jaehoon and Hong, Sungchul and Jeong, Seongsu and Kim, Sangmin and Cho, Hyoungsig and Hong, Seunghwan and Heo, Joon},
	month = jun,
	year = {2014},
	keywords = {Contents: BIM, FM Processes: AEC-FM},
	pages = {68--77},
	file = {Jung et al_2014_Productive modeling for development of as-built BIM of existing indoor.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/FXZMN4M4/Jung et al_2014_Productive modeling for development of as-built BIM of existing indoor.pdf:application/pdf;ScienceDirect Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/A2BEJ55J/S0926580514000466.html:text/html}
}

@article{irizarry_ambient_2014,
	title = {Ambient intelligence environments for accessing building information: {A} healthcare facility management scenario},
	volume = {32},
	shorttitle = {Ambient intelligence environments for accessing building information},
	doi = {10.1108/F-05-2012-0034},
	abstract = {Purpose ‐ Healthcare facility managers work in complex and dynamic environments where critical decisions are constantly made. Providing them with enhanced decision support systems would result in a positive impact on the productivity and success of the projects they undertake, as well as the sustainability of critical healthcare infrastructure. The purpose of this paper is to propose a conceptual ambient intelligent environment for enhancing the decision-making process of the facility managers. This low-cost data-rich environment would use building information modeling (BIM) and mobile augmented reality (MAR) as technological bases for the natural human-computer interfaces and aerial drones as technological tools. Design/methodology/approach ‐ This paper presents a scenario for the integration of augmented reality (AR) and building information modeling (BIM) to build an ambient intelligent (AmI) environment for facility managers where mobile, natural, user interfaces would provide the users with required data to facilitate their critical decision-making process. The technological requirements for having such an intelligent environment are also discussed. Findings ‐ The proposed BIM-MAR-based approach is capable of enhancing maintenance related practices for facility managers who are mobile to integrate with their facilities' intelligent environment. This approach is also capable of providing a collaborative environment in which different stakeholders, across geographically distributed areas, could work together to solve facility management tasks. Originality/value ‐ In this paper ambient intelligence will be considered for the first time in the area of healthcare facility management practices to provide facility managers with an intelligent BIM-based environment to access facility information and consequently enhance their decision-making process.},
	number = {3-4},
	journal = {Facilities},
	author = {Irizarry, Javier and Gheisari, Masoud and Williams, Graceline and Roper, Kathy},
	month = jan,
	year = {2014},
	keywords = {Contents: BIM, FM Processes: Information Management, Good Univ., System: Mobile AR},
	pages = {120--138},
	file = {Irizarry et al_2014_Ambient intelligence environments for accessing building information.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/VZQI72RB/Irizarry et al_2014_Ambient intelligence environments for accessing building information.pdf:application/pdf}
}

@article{eadie_bim_2013,
	title = {{BIM} implementation throughout the {UK} construction project lifecycle: {An} analysis},
	volume = {36},
	issn = {0926-5805},
	shorttitle = {{BIM} implementation throughout the {UK} construction project lifecycle},
	url = {http://www.sciencedirect.com/science/article/pii/S0926580513001507},
	doi = {10.1016/j.autcon.2013.09.001},
	abstract = {Substantial impacts through BIM implementation may be achieved throughout all stages of the construction process. The paper measures BIM use throughout the project lifecycle, confirming BIM is most often used in the early stages with progressively less use in the latter stages. This research demonstrates via 92 responses from a sample of BIM users that collaboration aspects produce the highest positive impact. The process aspects are more important than the software technology. BIM necessitates investment in software and training however, smaller practices can afford it. Stakeholder financial benefits are ranked concluding that clients benefit most financially from BIM followed by Facilities Managers. Despite this, over 70\% do not provide a 3D model and Cobie dataset at the conclusion of a project. Identification of Key Performance Indicators currently being used for BIM is provided and findings indicate a lack of industry expertise and training providing an opportunity for education providers.},
	urldate = {2015-07-25},
	journal = {Automation in Construction},
	author = {Eadie, Robert and Browne, Mike and Odeyinka, Henry and McKeown, Clare and McNiff, Sean},
	month = dec,
	year = {2013},
	keywords = {Contents: BIM, FM Processes: AEC-FM},
	pages = {145--151},
	file = {Eadie et al_2013_BIM implementation throughout the UK construction project lifecycle.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/H7M7B8IS/Eadie et al_2013_BIM implementation throughout the UK construction project lifecycle.pdf:application/pdf;ScienceDirect Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/AX6ENPKH/S0926580513001507.html:text/html}
}

@article{irizarry_infospot:_2013,
	series = {Augmented {Reality} in {Architecture}, {Engineering}, and {Construction}},
	title = {{InfoSPOT}: {A} mobile {Augmented} {Reality} method for accessing building information through a situation awareness approach},
	volume = {33},
	issn = {0926-5805},
	shorttitle = {{InfoSPOT}},
	url = {http://www.sciencedirect.com/science/article/pii/S0926580512001513},
	doi = {10.1016/j.autcon.2012.09.002},
	abstract = {The Architecture, Engineering, Construction, and Owner/Operator (AECO) industry is constantly searching for new methods for increasing efficiency and productivity. Facility Managers (FMs), as a part of the owner/operator role, work in complex and dynamic environments where critical decisions are constantly made. This decision-making process and its consequent performance can be improved by enhancing Situation Awareness (SA) of the FMs through new digital technologies. In this paper, InfoSPOT (Information Surveyed Point for Observation and Tracking), is recommended to FMs as a mobile Augmented Reality (AR) tool for accessing information about the facilities they maintain. AR has been considered as a viable option to reduce inefficiencies of data overload by providing FMs with a SA-based tool for visualizing their “real-world” environment with added interactive data. A prototype of the AR application was developed and a user participation experiment and analysis conducted to evaluate the features of InfoSPOT. This innovative application of AR has the potential to improve construction practices, and in this case, facility management.},
	urldate = {2015-07-25},
	journal = {Automation in Construction},
	author = {Irizarry, Javier and Gheisari, Masoud and Williams, Graceline and Walker, Bruce N.},
	month = aug,
	year = {2013},
	keywords = {AEC/FM: FM, Contents: BIM, FM Processes: Information Management, Good Univ., System: Mobile AR},
	pages = {11--23},
	file = {Irizarry et al_2013_InfoSPOT.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/WC74875W/Irizarry et al_2013_InfoSPOT.pdf:application/pdf;ScienceDirect Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/EXIKB3RR/S0926580512001513.html:text/html}
}

@article{saidi_value_????,
	title = {The value of handheld computers in construction},
	volume = {13},
	journal = {EVALUATION},
	author = {Saidi, K and Haas, Carl T and Balli, Nicole A},
	keywords = {System: Mobile App.},
	pages = {14},
	file = {Saidi et al_The value of handheld computers in construction.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/N5XNSBMC/Saidi et al_The value of handheld computers in construction.pdf:application/pdf}
}

@article{hollenbeck_multilevel_1995,
	title = {Multilevel theory of team decision making: {Decision} performance in teams incorporating distributed expertise},
	volume = {80},
	copyright = {(c) 2015 APA, all rights reserved},
	issn = {1939-1854(Electronic);0021-9010(Print)},
	shorttitle = {Multilevel theory of team decision making},
	doi = {10.1037/0021-9010.80.2.292},
	abstract = {The purpose of this research was to develop and test a theory of decision-making performance for hierarchical teams with distributed expertise. This theory identifies 3 core team-level constructs (team informity, staff validity, and hierarchical sensitivity) and 3 constructs below the team level that are central to decision-making accuracy in hierarchical teams with distributed expertise. Two studies are presented to test the proposed theory. A total of 492 college students worked on a computerized command-and-control simulator. Results from these studies are discussed in light of the theory. Similarities and differences in results across the 2 studies are discussed, as are potential modifications of the theory considering the data. Finally, implications of the theory for applied team contexts are elaborated.},
	number = {2},
	journal = {Journal of Applied Psychology},
	author = {Hollenbeck, John R. and Ilgen, Daniel R. and Sego, Douglas J. and Hedlund, Jennifer and Major, Debra A. and Phillips, Jean},
	year = {1995},
	keywords = {*Group Decision Making, *Job Experience Level, Theories},
	pages = {292--316}
}

@article{ko_web-based_2013,
	title = {Web-based radio frequency identification facility management systems},
	volume = {9},
	issn = {1573-2479},
	url = {http://dx.doi.org/10.1080/15732479.2010.546804},
	doi = {10.1080/15732479.2010.546804},
	abstract = {The operational life of a facility is extended through regular functional maintenance. The objective of this study is to enhance facility management efficiency using radio frequency identification (RFID) technology. A data management module is first developed to collect maintenance records. A statistical module is then established to graphically display the collected data. Maintenance activities are sequenced using a scheduling module to ensure that the facility functions normally. A forecast module is developed using fuzzy neural networks to avoid facility malfunction before the next maintenance. These four modules are integrated into a web-based RFID facility management system. System performance is validated using an actual building. Two RFID apparatuses are invented based on operational needs when implementing the developed system. The validation results show that integrating RFID technology with a web-based system, database, scheduling theory, artificial intelligence and enhancing apparatuses can improve facility maintenance efficiency. This study is one of the first researches providing a comprehensive solution for enhancing facility management efficiency.},
	number = {5},
	urldate = {2015-08-02},
	journal = {Structure and Infrastructure Engineering},
	author = {Ko, Chien-Ho and Pan, Nang-Fei and Chiou, Chuang-Chun},
	month = may,
	year = {2013},
	pages = {465--480},
	file = {Ko et al_2013_Web-based radio frequency identification facility management systems.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/6PHPHI5W/Ko et al_2013_Web-based radio frequency identification facility management systems.pdf:application/pdf;Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/P2QW5GXU/15732479.2010.html:text/html}
}

@article{hou_combining_2014-1,
	title = {Combining {Photogrammetry} and {Augmented} {Reality} {Towards} an {Integrated} {Facility} {Management} {System} for the {Oil} {Industry}},
	volume = {102},
	issn = {0018-9219},
	doi = {10.1109/JPROC.2013.2295327},
	abstract = {The capabilities of applying smart information management systems for facility management (FM) in oil refining context have not yet been fully exploited. This paper presents a study that investigates the applicability of integrating advanced technologies such as augmented virtuality (AV), augmented reality (AR), and server-sustained information modeling (IM) in facilitating FM activities for a petroleum refinery. The paper starts with a thorough review on previous work in which multiple information processing technologies are applied to aid FM. The following section presents the conceivable merits when the novel visualization is formulated to enhance the conventional IM application. It then proposes a novel system framework based on technological feasibility and further describes the development of a system prototype that boosts immersive and interactive experiences to FM toward a multitude of electrical components. It is noted that this paper focuses on the method for the technological realization of the system. With the successful development of the system, it is able to deal with the management of complex information flows, support the users' navigation in geo-coordinates, and enables a succinct smart IM interface with switchable AV/AR scenes. In view that IM has been proved suitable in supporting real-time communication and information management while AV/AR can be effectively used to improve the way how information is exhibited into real workspaces, the system proves the concept of IM+AV/AR in the context of FM in a refinery. Future work will be conducted on the evaluation of system effectiveness and system optimization, with the aim of functional improvement and performing a feasibility study.},
	number = {2},
	journal = {Proceedings of the IEEE},
	author = {Hou, Lei and Wang, Ying and Wang, Xiangyu and Maynard, N. and Cameron, I. and Zhang, Shaohua and Maynard, Y.},
	month = feb,
	year = {2014},
	keywords = {Contents: Model, FM Processes: Information Management, System: AR/VR},
	pages = {204--220},
	file = {Hou et al_2014_Combining Photogrammetry and Augmented Reality Towards an Integrated Facility.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/RNXK2JPD/Hou et al_2014_Combining Photogrammetry and Augmented Reality Towards an Integrated Facility.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/Jonghoon_Seo/Zotero Repository/storage/5TKIQEMP/abs_all.html:text/html}
}

@article{olbrich_augmented_2013-1,
	title = {Augmented reality supporting user-centric building information management},
	volume = {29},
	issn = {0178-2789, 1432-2315},
	url = {http://link.springer.com/article/10.1007/s00371-013-0840-2},
	doi = {10.1007/s00371-013-0840-2},
	abstract = {The rapid development of geo-referenced information changed the way on how we access and interlink data. Smartphones as enabling devices for information access are main driving factor. Thus, the hash key to information is the actual position registered via camera and sensory of the mobile device. A rising technology in this context is Augmented Reality (AR) as its fuses the real world captured with the smartphone camera with geo-referenced data. The technological building blocks analyse the intrinsic sensor data (camera, GPS, inertial) to derive a detailed pose of the smartphone aiming to align geo-referenced information to our real environment. In particular, this is interesting to applications where 3D models are used in planning and organization processes as, e.g., facility management. Here, Building Information Models (BIM) were established in order to hold “as built” information, but also to manage the vast amount of additional information coming with the design, such as building components, properties, maintenance logs, documentation, etc. One challenge is to enable stakeholders involved in the overall building lifecycle to get mobile access to the management system within on-site inspections and to automatise feedback of newly generated information into the BIM. This paper describes a new AR framework that offers on-site access to BIM information and user centric annotation mechanism.},
	language = {en},
	number = {10},
	urldate = {2015-07-25},
	journal = {The Visual Computer},
	author = {Olbrich, Manuel and Graf, Holger and Kahn, Svenja and Engelke, Timo and Keil, Jens and Riess, Patrick and Webel, Sabine and Bockholt, Ulrich and Picinbono, Guillaume},
	month = may,
	year = {2013},
	keywords = {Contents: BIM, FM Processes: Information Management, System: AR},
	pages = {1093--1105},
	file = {Olbrich et al_2013_Augmented reality supporting user-centric building information management.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/ZK4GKH44/Olbrich et al_2013_Augmented reality supporting user-centric building information management.pdf:application/pdf;Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/99XWFTHQ/s00371-013-0840-2.html:text/html}
}

@inproceedings{wimmer_curve:_2010,
	address = {New York, NY, USA},
	series = {{NordiCHI} '10},
	title = {Curve: {Revisiting} the {Digital} {Desk}},
	isbn = {978-1-60558-934-3},
	shorttitle = {Curve},
	url = {http://doi.acm.org/10.1145/1868914.1868977},
	doi = {10.1145/1868914.1868977},
	abstract = {Current desktop workspace environments consist of a vertical area (e.g., a screen with a virtual desktop) and a horizontal area (e.g., the physical desk). Daily working activities benefit from different intrinsic properties of both of these areas. However, both areas are distinct from each other, making data exchange between them cumbersome. Therefore, we present Curve, a novel interactive desktop environment, which combines advantages of vertical and horizontal working areas using a continous curved connection. This connection offers new ways of direct multi-touch interaction and new ways of information visualization. We describe our basic design, the ergonomic adaptions we made, and discuss technical challenges we met and expect to meet while building and configuring the system.},
	urldate = {2014-03-12},
	booktitle = {Proceedings of the 6th {Nordic} {Conference} on {Human}-{Computer} {Interaction}: {Extending} {Boundaries}},
	publisher = {ACM},
	author = {Wimmer, Raphael and Hennecke, Fabian and Schulz, Florian and Boring, Sebastian and Butz, Andreas and Hußmann, Heinrich},
	year = {2010},
	pages = {561--570},
	file = {ACM Full Text PDF:/Users/Jonghoon_Seo/Zotero Repository/storage/34S3XGP6/Wimmer et al. - 2010 - Curve Revisiting the Digital Desk.pdf:application/pdf}
}

@inproceedings{coram_astrotouch:_2013,
	address = {New York, NY, USA},
	series = {{ITS} '13},
	title = {{AstroTouch}: {A} {Multi}-touch {Digital} {Desktop} for {Astrodynamics}},
	isbn = {978-1-4503-2271-3},
	shorttitle = {{AstroTouch}},
	url = {http://doi.acm.org/10.1145/2512349.2512793},
	doi = {10.1145/2512349.2512793},
	abstract = {In this paper, we present the design, implementation, and preliminary evaluation of AstroTouch, a prototype desktop surface application to support analysis and visualization in the field of astrodynamics. We describe the fundamental characteristics of this complex scientific domain and discuss how these characteristics, combined with an assessment of current research surrounding multi-touch and the digital desktop, informed the design of our system. We detail the prototype implementation and present the results of an initial design critique conducted with domain experts.},
	urldate = {2014-03-12},
	booktitle = {Proceedings of the 2013 {ACM} {International} {Conference} on {Interactive} {Tabletops} and {Surfaces}},
	publisher = {ACM},
	author = {Coram, Jamie L. and Iverson, Rob and Ackerman, Andrew},
	year = {2013},
	pages = {11--14},
	file = {ACM Full Text PDF:/Users/Jonghoon_Seo/Zotero Repository/storage/9BQI5C3P/Coram et al. - 2013 - AstroTouch A Multi-touch Digital Desktop for Astr.pdf:application/pdf}
}

@inproceedings{benko_miragetable:_2012,
	address = {New York, NY, USA},
	series = {{CHI} '12},
	title = {{MirageTable}: {Freehand} {Interaction} on a {Projected} {Augmented} {Reality} {Tabletop}},
	isbn = {978-1-4503-1015-4},
	shorttitle = {{MirageTable}},
	url = {http://doi.acm.org/10.1145/2207676.2207704},
	doi = {10.1145/2207676.2207704},
	abstract = {Instrumented with a single depth camera, a stereoscopic projector, and a curved screen, MirageTable is an interactive system designed to merge real and virtual worlds into a single spatially registered experience on top of a table. Our depth camera tracks the user's eyes and performs a real-time capture of both the shape and the appearance of any object placed in front of the camera (including user's body and hands). This real-time capture enables perspective stereoscopic 3D visualizations to a single user that account for deformations caused by physical objects on the table. In addition, the user can interact with virtual objects through physically-realistic freehand actions without any gloves, trackers, or instruments. We illustrate these unique capabilities through three application examples: virtual 3D model creation, interactive gaming with real and virtual objects, and a 3D teleconferencing experience that not only presents a 3D view of a remote person, but also a seamless 3D shared task space. We also evaluated the user's perception of projected 3D objects in our system, which confirmed that the users can correctly perceive such objects even when they are projected over different background colors and geometries (e.g., gaps, drops).},
	urldate = {2014-03-12},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Benko, Hrvoje and Jota, Ricardo and Wilson, Andrew},
	year = {2012},
	pages = {199--208},
	file = {ACM Full Text PDF:/Users/Jonghoon_Seo/Zotero Repository/storage/JK7D6M9G/Benko et al. - 2012 - MirageTable Freehand Interaction on a Projected A.pdf:application/pdf}
}

@inproceedings{weiss_benddesk:_2010,
	address = {New York, NY, USA},
	series = {{ITS} '10},
	title = {{BendDesk}: {Dragging} {Across} the {Curve}},
	isbn = {978-1-4503-0399-6},
	shorttitle = {{BendDesk}},
	url = {http://doi.acm.org/10.1145/1936652.1936654},
	doi = {10.1145/1936652.1936654},
	abstract = {We present BendDesk, a hybrid interactive desk system that combines a horizontal and a vertical interactive surface via a curve. The system provides seamless touch input across its entire area. We explain scalable algorithms that provide graphical output and multi-touch input on a curved surface. In three tasks we investigate the performance of dragging gestures across the curve, as well as the virtual aiming at targets. Our main findings are: 1) Dragging across a curve is significantly slower than on flat surfaces. 2) The smaller the entrance angle when dragging across the curve, the longer the average trajectory and the higher the variance of trajectories across users. 3) The curved shape of the system impairs virtual aiming at targets.},
	urldate = {2014-03-12},
	booktitle = {{ACM} {International} {Conference} on {Interactive} {Tabletops} and {Surfaces}},
	publisher = {ACM},
	author = {Weiss, Malte and Voelker, Simon and Sutter, Christine and Borchers, Jan},
	year = {2010},
	pages = {1--10},
	file = {ACM Full Text PDF:/Users/Jonghoon_Seo/Zotero Repository/storage/IAFR4VQA/Weiss et al. - 2010 - BendDesk Dragging Across the Curve.pdf:application/pdf}
}

@incollection{grossman__2010,
	series = {Human-{Computer} {Interaction} {Series}},
	title = {On, {Above}, and {Beyond}: {Taking} {Tabletops} to the {Third} {Dimension}},
	shorttitle = {On, {Above}, and {Beyond}},
	url = {http://link.springer.com/chapter/10.1007/978-1-84996-113-4_12},
	abstract = {Extending the tabletop to the third dimension has the potential to improve the quality of applications involving 3D data and tasks. Recognizing this, a number of researchers have proposed a myriad of display and input metaphors. However a standardized and cohesive approach has yet to evolve. Furthermore, the majority of these applications and the related research results are scattered across various research areas and communities, and lack a common framework. In this chapter, we survey previous 3D tabletops systems, and classify this work within a newly defined taxonomy. We then discuss the design guidelines which should be applied to the various areas of the taxonomy. Our contribution is the synthesis of numerous research results into a cohesive framework, and the discussion of interaction issues and design guidelines which apply. Furthermore, our work provides a clear understanding of what approaches have been taken, and exposes new routes for potential research, within the realm of interactive 3D tabletops.},
	urldate = {2014-03-05},
	booktitle = {Tabletops-{Horizontal} {Interactive} {Displays}},
	publisher = {Springer},
	author = {Grossman, Tovi and Wigdor, Daniel},
	year = {2010},
	pages = {277--299},
	file = {chp%3A10.1007%2F978-1-84996-113-4_12.pdf:/Users/Jonghoon_Seo/Zotero Repository/storage/5HF83TD3/chp3A10.10072F978-1-84996-113-4_12.pdf:application/pdf;Snapshot:/Users/Jonghoon_Seo/Zotero Repository/storage/EPF92CEW/978-1-84996-113-4_12.html:text/html}
}